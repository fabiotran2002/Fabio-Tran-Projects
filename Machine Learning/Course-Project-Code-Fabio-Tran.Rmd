---
title: "Course Project"
author: "Fabio Tran"
date: '2022-03-26'
output: html_document
---

**Imported the White Wine Quality Data Set from the UCI Machine Learning Repository**

```{r}
setwd("C:/Users/fabio_c80y/OneDrive/Desktop/Machine Learning Project")
data = read.csv("WhiteWineQualityDataset.csv")
```

**Linear Regression**

Created a Linear Regression model including all predictors from the data set.

```{r}
quality_regression = lm(quality ~ ï..fixed.acidity + volatile.acidity + citric.acid + residual.sugar + chlorides + free.sulfur.dioxide + total.sulfur.dioxide + density + pH + sulphates + alcohol, data = data)
```

To only include the most statistically significant predictors in the Linear Regression model, I used the summary() function to compare coefficient p-values. The predictors: citric.acid, chlorides, and total.sulfur.dioxide had high p-values greater than 0.05 which does not prove statistical significance so I choose to ignore them. 

```{r}
summary(quality_regression)
```

Created several models starting with one predictor and adding on until all predictors are included. Then, performed Leave-One-Out-Cross-Validation (LOOCV) to determine which model yields the lowest CV or test error. Model 8 has the lowest LOOCV error rate of 0.5632469 so it is the most accurate model out of the 8 models.

Model 1:

```{r}
list = vector()
for (i in 1:4898){
  training = data[-c(i), ]
  test = data[c(i), ]
  linear_regression = lm(quality ~ ï..fixed.acidity, data = data)
  input = data.frame(test$ï..fixed.acidity)
  colnames(input) = "ï..fixed.acidity"
  predicted_value = predict(linear_regression, newdata = input)
  actual_value = test$quality
  MSE = (actual_value - predicted_value)^2
  list = c(list, MSE)
}
mean(list)
```

Model 2:

```{r}
list = vector()
for (i in 1:4898){
  training = data[-c(i), ]
  test = data[c(i), ]
  linear_regression = lm(quality ~ ï..fixed.acidity + volatile.acidity, data = data)
  input = data.frame(test$ï..fixed.acidity, test$volatile.acidity)
  colnames(input) = c("ï..fixed.acidity", "volatile.acidity")
  predicted_value = predict(linear_regression, newdata = input)
  actual_value = test$quality
  MSE = (actual_value - predicted_value)^2
  list = c(list, MSE)
}
mean(list)
```

Model 3:

```{r}
list = vector()
for (i in 1:4898){
  training = data[-c(i), ]
  test = data[c(i), ]
  linear_regression = lm(quality ~ ï..fixed.acidity + volatile.acidity + residual.sugar, data = data)
  input = data.frame(test$ï..fixed.acidity, test$volatile.acidity, test$residual.sugar)
  colnames(input) = c("ï..fixed.acidity", "volatile.acidity", "residual.sugar")
  predicted_value = predict(linear_regression, newdata = input)
  actual_value = test$quality
  MSE = (actual_value - predicted_value)^2
  list = c(list, MSE)
}
mean(list)
```

Model 4:

```{r}
list = vector()
for (i in 1:4898){
  training = data[-c(i), ]
  test = data[c(i), ]
  linear_regression = lm(quality ~ ï..fixed.acidity + volatile.acidity + residual.sugar + free.sulfur.dioxide, data = data)
  input = data.frame(test$ï..fixed.acidity, test$volatile.acidity, test$residual.sugar, test$free.sulfur.dioxide)
  colnames(input) = c("ï..fixed.acidity", "volatile.acidity", "residual.sugar", "free.sulfur.dioxide")
  predicted_value = predict(linear_regression, newdata = input)
  actual_value = test$quality
  MSE = (actual_value - predicted_value)^2
  list = c(list, MSE)
}
mean(list)
```

Model 5:

```{r}
list = vector()
for (i in 1:4898){
  training = data[-c(i), ]
  test = data[c(i), ]
  linear_regression = lm(quality ~ ï..fixed.acidity + volatile.acidity + residual.sugar + free.sulfur.dioxide + density, data = data)
  input = data.frame(test$ï..fixed.acidity, test$volatile.acidity, test$residual.sugar, test$free.sulfur.dioxide, test$density)
  colnames(input) = c("ï..fixed.acidity", "volatile.acidity", "residual.sugar", "free.sulfur.dioxide", "density")
  predicted_value = predict(linear_regression, newdata = input)
  actual_value = test$quality
  MSE = (actual_value - predicted_value)^2
  list = c(list, MSE)
}
mean(list)
```

Model 6:

```{r}
list = vector()
for (i in 1:4898){
  training = data[-c(i), ]
  test = data[c(i), ]
  linear_regression = lm(quality ~ ï..fixed.acidity + volatile.acidity + residual.sugar + free.sulfur.dioxide + density + pH, data = data)
  input = data.frame(test$ï..fixed.acidity, test$volatile.acidity, test$residual.sugar, test$free.sulfur.dioxide, test$density, test$pH)
  colnames(input) = c("ï..fixed.acidity", "volatile.acidity", "residual.sugar", "free.sulfur.dioxide", "density", "pH")
  predicted_value = predict(linear_regression, newdata = input)
  actual_value = test$quality
  MSE = (actual_value - predicted_value)^2
  list = c(list, MSE)
}
mean(list)
```

Model 7:

```{r}
list = vector()
for (i in 1:4898){
  training = data[-c(i), ]
  test = data[c(i), ]
  linear_regression = lm(quality ~ ï..fixed.acidity + volatile.acidity + residual.sugar + free.sulfur.dioxide + density + pH + sulphates, data = data)
  input = data.frame(test$ï..fixed.acidity, test$volatile.acidity, test$residual.sugar, test$free.sulfur.dioxide, test$density, test$pH, test$sulphates)
  colnames(input) = c("ï..fixed.acidity", "volatile.acidity", "residual.sugar", "free.sulfur.dioxide", "density", "pH", "sulphates")
  predicted_value = predict(linear_regression, newdata = input)
  actual_value = test$quality
  MSE = (actual_value - predicted_value)^2
  list = c(list, MSE)
}
mean(list)
```

Model 8:

```{r}
list = vector()
for (i in 1:4898){
  training = data[-c(i), ]
  test = data[c(i), ]
  linear_regression = lm(quality ~ ï..fixed.acidity + volatile.acidity + residual.sugar + free.sulfur.dioxide + density + pH + sulphates + alcohol, data = data)
  input = data.frame(test$ï..fixed.acidity, test$volatile.acidity, test$residual.sugar, test$free.sulfur.dioxide, test$density, test$pH, test$sulphates, test$alcohol)
  colnames(input) = c("ï..fixed.acidity", "volatile.acidity", "residual.sugar", "free.sulfur.dioxide", "density", "pH", "sulphates", "alcohol")
  predicted_value = predict(linear_regression, newdata = input)
  actual_value = test$quality
  MSE = (actual_value - predicted_value)^2
  list = c(list, MSE)
}
mean(list)
```

**Logistic Regression**

Converted the output variable quality to a binary variable called quality01 where quality value 0-5 will indicate low quality and 6-10 indicates high quality.

```{r}
quality01 = as.numeric(data$quality > 5)
new_data = data.frame(data, quality01)
new_data$quality = NULL
```

Created a Logistic Regression model using the same predictors from model 8 of the Linear Regression section. The observations are split in half to be used as training and test data respectively. The model is trained with the training data and is used to classify each test data observation. This yielded a test error rate of 0.2097959 which means about 20.97% of the test data observations are classified incorrectly.

```{r}
new_data_training = new_data[-c(1:2449), ]
new_data_test = new_data[c(2449:4898), ]

logistic_regression = glm(quality01 ~ ï..fixed.acidity + volatile.acidity + residual.sugar + free.sulfur.dioxide + density + pH + sulphates + alcohol, data = new_data_training, family = binomial)

my_prob_results_test = predict(logistic_regression, new_data_test, type = "response")
my_classification_test = ifelse(my_prob_results_test > 0.50, "1", "0")
table(my_classification_test, new_data_test$quality01)
mean(my_classification_test != new_data_test$quality01)
```

**K-Nearest Neighbors**

Created a K-Nearest Neighbor classification model using the same predictors as model 8 from the Linear Regression section and the binary quality variable created from the Logistic Regression model. The model is trained by using half of the observations in the data set and the test error is calculated by using the model to classify the other half. The lowest test error rate was 0.2151899 when k = 1. 

```{r}
library(class)
standardized_data = scale(new_data[, c("ï..fixed.acidity", "volatile.acidity", "residual.sugar", "free.sulfur.dioxide", "density", "pH", "sulphates", "alcohol")])
set.seed(1)
v = sort(sample(1:4898, 2449))
train.X = standardized_data[v, ]
test.X = standardized_data[-v, ]
train.Y = new_data$quality01[v]
test.Y = new_data$quality01[-v]
set.seed(1)

knn.pred = knn(train.X, test.X, train.Y, k = 1)
m = mean(test.Y != knn.pred)
print(m)

knn.pred = knn(train.X, test.X, train.Y, k = 2)
m = mean(test.Y != knn.pred)
print(m)

knn.pred = knn(train.X, test.X, train.Y, k = 3)
m = mean(test.Y != knn.pred)
print(m)

knn.pred = knn(train.X, test.X, train.Y, k = 4)
m = mean(test.Y != knn.pred)
print(m)

knn.pred = knn(train.X, test.X, train.Y, k = 5)
m = mean(test.Y != knn.pred)
print(m)
```

Used the KNN model to make a prediction for an observation with certain parameter values. The outcome is 0 which means the observation is classified as low quality.

```{r}
newTest.X = data.frame(ï..fixed.acidity = c(6.2), volatile.acidity = c(0.120), residual.sugar = c(5.40), free.sulfur.dioxide = c(47.0), density = c(0.9914), pH = c(3.25), sulphates = c(0.45), alcohol = c(11.4))
knn.pred = knn(train.X, newTest.X, train.Y, k = 1)
knn.pred
```

**Decision Tree**

Created a Decision Tree model to predict the variable "quality" based on the training data which is half of the data set.

```{r}
install.packages("tree", repos = "http://cran.us.r-project.org")
library(tree)

data_training = data[-c(1:2449), ]
data_test = data[c(2449:4898), ]

tree_training = tree(quality ~ ., data_training)

summary(tree_training)
plot(tree_training)
text(tree_training, pretty = 0)
```

Calculated test error of this model using the other half of the data set as test data. The test mean squared error is calculated to be 0.4839659.

```{r}
predicted_value = predict(tree_training, newdata = data_test)
test_MSE = mean((predicted_value - data_test$quality)^2)
test_MSE
```

Used cross-validation to determine the best choice for the number of terminal nodes (leaves) and then pruned the model to that specification. The plot represents cross-validation error versus the number of terminal nodes in the tree. 

```{r}
cv_quality = cv.tree(tree_training)
plot(cv_quality$size, cv_quality$dev, type = 'b')

prune_tree_training = prune.tree(tree_training, best = 7)
plot(prune_tree_training)
text(prune_tree_training, pretty = 0)
```








